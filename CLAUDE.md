# CLAUDE.md

This file provides guidance to Claude Code (claude.ai/code) when working with code in this repository.

## Project Overview

Crypto Map Pay App Widget is a Nuxt 4 application that helps users discover crypto-friendly locations in Lugano. It uses PostgreSQL with PostGIS for geospatial queries and pgvector for semantic search via OpenAI embeddings. The app features hybrid search combining PostgreSQL full-text search with AI-powered category matching. Deployed on NuxtHub/Cloudflare and styled with UnoCSS using the Nimiq design system.

## Development Commands

```bash
# Development
pnpm run dev              # Start dev server on localhost:3000
pnpm run build            # Build for production
pnpm run preview          # Preview production build

# Database (requires .env file in project root)
pnpm run db:start         # Start PostgreSQL + PostGIS with Docker
pnpm run db:stop          # Stop database
pnpm run db:restart       # Restart database (useful for reseeding)
pnpm run db:generate      # Generate Drizzle migrations from schema changes

# Code Quality
pnpm run lint             # Run ESLint with cache
pnpm run lint:fix         # Auto-fix ESLint issues
pnpm run typecheck        # Run TypeScript type checking
```

## Architecture

### Database Architecture

The app uses **PostgreSQL with PostGIS and pgvector** and a normalized relational schema with three tables:

1. **`categories`** - Stores all unique Google Maps category types with vector embeddings
   - Schema: `id` (text, PK), `name` (text), `icon` (text), `embedding` (vector(1536)), `createdAt` (timestamp)
   - **Vector embeddings** enable semantic search - "coffee shop" matches "cafe" without exact text match
   - Embeddings are generated via OpenAI text-embedding-3-small (1536 dimensions)
   - Categories are seeded from `database/seeds/categories.sql`

2. **`locations`** - Main location data with PostGIS geometry and opening hours
   - Primary key: auto-generated UUID
   - **Uses PostGIS `geometry(point, 4326)` for location** instead of separate lat/lng columns
   - GIST spatial index on `location` column for efficient proximity queries
   - Schema: `uuid`, `name`, `address`, `location` (geometry point), `rating`, `photo`, `gmapsPlaceId` (unique), `gmapsUrl`, `website`, `source`, `timezone`, `openingHours`, `createdAt`, `updatedAt`
   - `timezone`: IANA timezone identifier (e.g., "Europe/Zurich")
   - `openingHours`: JSON string with weekly opening hours
   - Extract coordinates using `ST_X(location)` for longitude and `ST_Y(location)` for latitude

3. **`location_categories`** - Junction table for many-to-many relationship
   - Links locations to categories via foreign keys with cascade delete
   - Composite primary key on (locationUuid, categoryId)
   - Indexed on both foreign keys for efficient joins

**Important**: When adding locations:

1. Insert into `locations` table with location as `{x: longitude, y: latitude}`
2. Insert corresponding rows into `location_categories` junction table
3. PostGIS automatically handles the geometry conversion

### Database Seeding

- **Automatic seeding** via Docker Compose when starting the PostgreSQL database
- Migrations are stored in `database/migrations/` (generated by Drizzle)
- Seed files are stored in `database/seeds/`:
  - `categories.sql` - All Google Maps category types with icon mappings and vector embeddings
  - `sources/dummy.sql` - Dummy location data for testing
- The seeding process (executed by Docker):
  1. `init.sh` - Creates PostGIS and pgvector extensions, roles, and permissions
  2. `run-migrations.sh` - Applies Drizzle migrations to create tables
  3. `rls-policies.sql` - Applies Row Level Security policies
  4. Seeds categories with embeddings and dummy location data
- To start/restart database: `pnpm run db:start`
- To regenerate migrations after schema changes: `pnpm run db:generate`

### Search System

The app implements **hybrid search** combining two approaches:

1. **Text Search** - PostgreSQL Full-Text Search (FTS)
   - Uses `to_tsvector` and `to_tsquery` for fast text matching
   - Searches across location name and address fields
   - `ts_headline` generates highlighted snippets with `<mark>` tags
   - Used in autocomplete for instant results (10-50ms)

2. **Semantic Search** - Vector similarity via pgvector
   - Query → OpenAI embedding → Find similar category embeddings
   - Uses cosine similarity with threshold 0.7 (configurable in `server/utils/search.ts`)
   - Returns top 5 matching categories
   - Then fetches locations belonging to those categories

3. **Embedding Cache** - NuxtHub KV
   - Permanent cache (no TTL) for query embeddings
   - Reduces OpenAI API costs and latency
   - Autocomplete precomputes embeddings in background
   - Cache key: `embedding:${query.trim().toLowerCase()}`

### API Endpoints

**`GET /api/categories`**

- Returns all categories from the database
- Used to populate filter UI
- Returns: `Array<{id, name, icon}>`

**`GET /api/locations/[uuid]`**

- Fetch single location by UUID
- Path parameter: `uuid` (validated as UUID)
- Uses `json_agg` with `json_build_object` to aggregate categories as JSON array
- Returns: Full location object with `categories: Array<{id, name, icon}>`

**`GET /api/search`**

- Hybrid search combining text FTS and semantic category matching
- Query params:
  - `q` (required): Search query string
  - `lat`/`lng` (optional): User location for future distance sorting (currently logged only)
  - `categories` (optional): Array of category IDs to filter by
  - `openNow` (optional): Boolean to filter by opening hours
- If lat/lng not provided, attempts Cloudflare IP geolocation via `locateByHost()`
- Returns empty array if query is empty
- **Search flow:**
  1. Parallel: `searchLocationsByText()` + `searchSimilarCategories()`
  2. Fetch locations matching similar categories via `searchLocationsByCategories()`
  3. Merge results (text first, then semantic) and deduplicate by UUID
  4. Apply category filters if provided (all selected categories must match)
  5. Apply opening hours filter if `openNow=true`
- Uses PostgreSQL `STRING_AGG()` for comma-separated category IDs
- Extracts lat/lng from PostGIS geometry using `ST_Y()` and `ST_X()`
- Returns: `Array<SearchLocationResponse>` with `categoryIds` string and `categories` array

**`GET /api/search/autocomplete`**

- Fast text-only search for autocomplete dropdown
- Query params: `q` (required, min 2 chars)
- **Background task**: Calls `generateEmbeddingCached()` in fire-and-forget mode to precompute embedding
- Uses `searchLocationsByText()` with PostgreSQL FTS
- Returns: Same as search endpoint but includes `highlightedName` field with `<mark>` tags

### Styling System

The app uses **UnoCSS with Nimiq presets**:

- `presetOnmax()` - Base utilities
- `presetNimiq()` - Nimiq design system utilities and attributify mode
- Utilities are applied via **attributify syntax** directly on elements (e.g., `flex="~ col gap-16"`)
- Nimiq CSS provides the `f-` prefix utilities for consistent spacing/typography
- Custom utility examples: `f-mb-lg`, `f-py-xl`, `f-px-md`, `text="neutral-900 f-lg"`

### UI Components

- **Reka UI** is used for accessible components (Vue port of Radix UI)
- Auto-imported via `reka-ui/nuxt` module in nuxt.config.ts
- Example: `ToggleGroupRoot` + `ToggleGroupItem` for category filters
- Must use the `Root` component (e.g., `ToggleGroupRoot`, not `ToggleGroup`)

### Type Safety

- **Valibot** is used for runtime validation (not Zod)
- Query parameters are validated in API routes using `v.safeParse()`
- Example pattern: `v.pipe(v.string(), v.transform(Number), v.number())`
- Runtime config validation via `nuxt-safe-runtime-config` with Valibot schema

### Database Access

- Use `useDrizzle()` helper to get database instance
- Import schema as `tables` from `server/utils/drizzle.ts`
- Schema is defined in `database/schema.ts`
- Type exports: `Location`, `Category`, `LocationCategory`
- Connection uses `DATABASE_URL` from runtime config (Supabase PostgreSQL connection string)
- PostgreSQL-specific: Use `sql` tagged templates for PostGIS and pgvector queries
- PostGIS functions: `ST_X()`, `ST_Y()`, `ST_Distance()`, `ST_Within()`, etc.
- pgvector operators: `<=>` (cosine distance), `<->` (L2 distance), `<#>` (inner product)

### Server Utilities

- **`server/utils/search.ts`** - Search functions
  - `searchLocationsByText(query)` - PostgreSQL FTS with `ts_headline` highlighting
  - `searchSimilarCategories(query)` - Vector similarity search for categories
  - `searchLocationsByCategories(categoryIds)` - Fetch locations by category IDs
  - `locationSelect` - Reusable select object to avoid duplicating 20+ column definitions
  - `SIMILARITY_THRESHOLD` constant (0.7) - Adjust for more/fewer semantic results

- **`server/utils/embeddings.ts`** - OpenAI embedding generation
  - `generateEmbeddingCached(text)` - Generate or fetch cached embedding from NuxtHub KV
  - Model: `text-embedding-3-small` (1536 dimensions)
  - Cache key format: `embedding:${text.trim().toLowerCase()}`

- **`server/utils/open-now.ts`** - Opening hours filtering
  - `filterOpenNow(locations)` - Filter locations by current opening hours
  - Handles timezone conversion using location's `timezone` field
  - Parses `openingHours` JSON string

- **`server/utils/geoip.ts`** - GeoIP location service
  - `locateByHost(ip)` - Cloudflare IP geolocation fallback

- **`server/utils/drizzle.ts`** - Database utilities
  - `useDrizzle()` - Get database instance
  - `tables` export - All table schemas

## Key Patterns

### Adding New Locations

1. Add location data to `database/seeds/sources/dummy.sql` or create a new source SQL file
2. Categories must be valid Google Maps types (snake_case strings) from `database/seeds/categories.sql`
3. Use PostGIS `ST_SetSRID(ST_MakePoint(longitude, latitude), 4326)` for location geometry
4. Include `timezone` (IANA identifier like "Europe/Zurich") and optionally `openingHours` (JSON string)
5. Insert corresponding rows into `location_categories` junction table
6. Restart Docker Compose to apply changes: `pnpm run db:restart`

### Adding New Categories

1. Add to `database/seeds/categories.sql` with format: `INSERT INTO categories (id, name, icon, embedding) VALUES (...)`
2. Generate embedding using OpenAI text-embedding-3-small (1536-dim)
3. Store embedding as vector: `'[0.123, -0.456, ...]'::vector(1536)`
4. Category IDs use snake_case (e.g., "coffee_shop", "restaurant")
5. Restart database to apply: `pnpm run db:restart`

### Semantic Search Configuration

- **Similarity threshold**: Adjust `SIMILARITY_THRESHOLD` in `server/utils/search.ts` (default: 0.7)
  - Higher (0.8+): More precise matches, fewer results
  - Lower (0.6-): More results, may include less relevant categories
- **Top categories limit**: Currently returns top 5 similar categories (hardcoded in query `.limit(5)`)
- **Embedding model**: Changing model requires regenerating all category embeddings

### Category Filtering

- Categories use raw Google Maps types (e.g., "restaurant", "cafe", "lodging")
- UI displays formatted category names (underscores → spaces, title case)
- Backend stores raw snake_case IDs
- Filter logic: All selected categories must match (AND logic, not OR)

### Opening Hours Filtering

- `openNow` filter uses `server/utils/open-now.ts`
- Requires valid `timezone` and `openingHours` fields on locations
- Converts current time to location's timezone before checking hours
- Locations without opening hours data are excluded when filter is active

### Geolocation

- Cloudflare provides `cf-connecting-ip` header in production
- Dev environment requires manual lat/lng query params
- Currently location is retrieved but NOT used for distance sorting
- Future: Use `ST_Distance()` for proximity-based sorting

## Configuration Files

- **`nuxt.config.ts`** - Nuxt config with NuxtHub, UnoCSS, Reka UI modules, PostgreSQL runtime config
- **`drizzle.config.ts`** - PostgreSQL dialect, schema at `database/schema.ts`, migrations output to `database/migrations/`
- **`uno.config.ts`** - UnoCSS with Nimiq presets
- **`eslint.config.mjs`** - Antfu's ESLint config with Nuxt integration
- **`database/docker-compose.yml`** - Docker Compose setup for local PostgreSQL development
- **`database/init.sh`** - Initializes PostGIS extensions and permissions
- **`database/run-migrations.sh`** - Runs Drizzle migrations on container start
- **`database/rls-policies.sql`** - Row Level Security policies
- **`database/seeds/categories.sql`** - All Google Maps categories with icons
- **`database/seeds/sources/dummy.sql`** - Dummy location data

## Environment Variables

Required in `.env` (project root):

```env
# PostgreSQL Configuration (Supabase Remote - Pooler)
DATABASE_URL=postgresql://postgres.xxxxx:password@aws-1-eu-central-1.pooler.supabase.com:6543/postgres

# API Keys
GOOGLE_API_KEY=your_google_api_key
OPENAI_API_KEY=your_openai_api_key  # Required for semantic search embeddings
```

All variables are validated via `safeRuntimeConfig` using Valibot schema with `minLength(1)` to ensure non-empty values.

**Note**: Without `OPENAI_API_KEY`, semantic search will fail. Text search will still work.
